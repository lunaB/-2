# 단순 선형 회귀

#### Regression
Regression toward the mean 큰 데이터들 속에 튀는 데이터가 있어도 전체데이터의 평균으로 돌아가려는 특징이 있다.

#### Linear Regression
데이터를 가장 잘 대변하는 직선의 방정식을 찾는것.  
(x, y) 데이터를 사용하며 H(x) = Wx + b 모양을 갖습니다. 
우리가 학습을 시킬때 데이터를 x데이터를 넣어 나오는 H(x)값과 목표하던 y값과의 차이(H(x)-y)를 Cost혹은 Loss혹은 Error 라고 부르며 cost(W,b) 코스트함수(인수를 W로 사용합니다.)  
Linear Regression의 목적은 Cost값을 최대한 줄이는 것입니다. 그렇다면 임의의 X값을 넣었을때 학습한 데이터를 가장 잘대변하는 Y값을 얻을수 있겠죠?




