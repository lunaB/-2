# ConvNet의 Conv 레이어 만들기

#### 역사
convolutional 신경망은 고양이를 이용한 실험에서 아이디어를 얻었습니다.  
고양이에게 어떤 사진을 보여주었을때 뉴런들이 각자 활성화 되는 부분이 달랐습니다.  
즉 어떠한 사진을 볼때 모든 뉴런들 활성화 되지 않고 각 사진마다 활성화 되는 달랐다는 것입니다.  
그래서 각부분에 따라 각뉴런을 학습시킬수 있는 신경망을 개발하게 됩니다.  

#### convolutional layer
이는 filter를 사용해서 사진의 특정 부분을 자릅니다. (5*5*3) (3은 색상)  
그리고 (5*5*3)의 filter에서 한개의 값을 뽑아 냅니다.  
한개의 값을 뽑을때는 이전에 배웠던 신경망과 같은 원리로 만듭니다.  
보통 ReLU(Wx+b)를 사용한다고 합니다.  
이렇게 옆, 아레로 특정 칸만큼 움직이며 각각 값을 얻어냅니다.  

나머지 filter 계산에 대한 문제는 간단하기도하고 글로 정리하기도 쉽지 않아 정리하지 않습니다.

filter를 어떠한 이미지가 거치게 되면 이미지가 점점 작아집니다.  
이를막기위해 테두리에 pad를 넣어줍니다 테두리에 0으로 감싸주는 것이지요.  
그러면 같은 사이즈의 이미지를 얻을 수 있습니다.

각기 weight가 다른 filter를 여러개를 이용해 여러개의 filter이미지를 만듭니다.
여러 이미지가 겹친 모양처럼 되는 것을 상상 할수 있는데,  
이를 activation map이라고 부릅니다.

# ConvNet Max pooling 과 Full Network

#### Pool layer (sampling)
activation map의 filter layer를 resize를 해서 작게 만듭니다. 이것을 pooling이라고 합니다.  
작게만드는이유는 네트워크의 파라미터의 개수나 연산량을 줄이기 위해라고한다.  
또한 이는 오버피팅을 조절하는 효과도 가지고 있다.

#### Max pooling
특정의 구역을 격자 모양으로 나눕니다. EX(3*3) (겹치지 않게)  
그 구역에서 가장 큰 값을 추출하여 합칩니다.  
